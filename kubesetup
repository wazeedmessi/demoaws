first login to VM 
then sudo -i

apt update
apt upgrade

nano /etc/fstab 
comment the line /swap {#}

swapoff -a

vi /etc/modules-load.d/containerd.conf

overlay
br_netfilter

(paste above lines)

modprobe overlay
modprobe br_netfilter

vi /etc/sysctl.d/99-kubernetes-cri.conf

net.bridge.bridge-nf-call-iptables  = 1
net.ipv4.ip_forward                 = 1
net.bridge.bridge-nf-call-ip6tables = 1

sysctl --system

# Add Docker's official GPG key:

apt-get update

apt-get install ca-certificates curl gnupg

sudo install -m 0755 -d /etc/apt/keyrings

curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg

sudo chmod a+r /etc/apt/keyrings/docker.gpg

# Add the repository to Apt sources:

echo \
  "deb [arch="$(dpkg --print-architecture)" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
  "$(. /etc/os-release && echo "$VERSION_CODENAME")" stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

sudo apt-get update

apt-get install containerd.io

systemctl status containerd

# Configure containerd

mkdir -p /etc/containerd

containerd config default > /etc/containerd/config.toml

sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml

# Restart containerd

systemctl restart containerd

vi /etc/crictl.yaml

runtime-endpoint: unix:///run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
timeout: 2

Install kubernetes packages on all nodes.
=========================================
{ https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/ }


apt-get update

sudo apt-get install -y apt-transport-https ca-certificates curl gpg

curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.28/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

# This overwrites any existing configuration in /etc/apt/sources.list.d/kubernetes.list

echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.28/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list

sudo apt-get update

sudo apt-get install -y kubelet kubeadm kubectl

sudo apt-mark hold kubelet kubeadm kubectl

On control nodes (k8s master node)
=====================================

{* We are bootstrapping control plane node.
* "--pod-network-cidr" was changes here on local setup. Since my VMs are using same series network.
* So instead of applying the calico YAML files, first download them and update the CIDR of pod to be used cidr which ever "For example: 10.44.0.0/16     private class".}

kubeadm init --apiserver-advertise-address=192.168.0.69 --cri-socket=/run/containerd/containerd.sock --pod-network-cidr=10.44.0.0/16

mkdir -p $HOME/.kube

sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config

sudo chown $(id -u):$(id -g) $HOME/.kube/config

========
calico:      https://docs.tigera.io/calico/latest/getting-started/kubernetes/quickstart
========
wget https://raw.githubusercontent.com/projectcalico/calico/v3.26.3/manifests/tigera-operator.yaml

kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.3/manifests/tigera-operator.yaml

wget  https://raw.githubusercontent.com/projectcalico/calico/v3.26.3/manifests/custom-resources.yaml

kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.3/manifests/custom-resources.yaml

kubectl apply -f custom-resources.yaml

kubectl get nodes -o wide
